# -*- coding: utf-8 -*-
"""LR_Perceptrong_HL_from_scratch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dt6l9mt07uoOkV8aRPV6oFVQwZ50tlrJ
"""

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
import seaborn as sns
from sklearn.linear_model import SGDRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# Read in file
seoul_bike_data = pd.read_csv("https://raw.githubusercontent.com/shrutib55/cs4372_assignment1/main/SeoulBikeData.csv", encoding='ISO-8859-1')

seoul_bike_data.head()

# Generate pair plot
sns.pairplot(seoul_bike_data)

# Scale the data for SGD
scaler = StandardScaler()
y = seoul_bike_data['Rented Bike Count']
X = seoul_bike_data.drop(['Rented Bike Count', 'Date'], axis=1)
X = pd.get_dummies(X, drop_first=True)
X_scaled = scaler.fit_transform(X)

# Look at how the scaled data is distributed
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
X_scaled.describe()

# Look at correlation between all the variables
X_scale_full = X_scaled.copy()
X_scale_full['Rented Bike Count'] = y
correlation_matrix = X_scale_full.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True)

# Look at sorted correlations with the target variables to see which features to choose
correlation_with_y = correlation_matrix['Rented Bike Count'].sort_values(ascending=False)
print(correlation_with_y)

# Selecting features with a absolute value correlation with target variable above or equal to 0.2
features = ['Temperature(째C)', 'Hour', 'Dew point temperature(째C)', 'Seasons_Winter', 'Seasons_Summer', 'Solar Radiation (MJ/m2)', 'Humidity(%)', 'Visibility (10m)', 'Functioning Day_Yes']

X = X_scaled[features]

# Split into 80/20 train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=5)

X_train.shape, X_test.shape

"""Stochastic Gradient Descent"""



#hyperparameters
max_iter = 1000
tol = 1e-2
alpha = 0.001

# Run sgd with specified hyper parameters
sgd = SGDRegressor(max_iter=max_iter, tol=tol, alpha= alpha)
sgd.fit(X_train, y_train)

sgd.coef_

sgd.intercept_

y_train_pred = sgd.predict(X_train)
y_test_pred = sgd.predict(X_test)

# Look at training metrics
mse_train = mean_squared_error(y_train, y_train_pred)
mae_train = mean_absolute_error(y_train, y_train_pred)
ev_train = explained_variance_score(y_train, y_train_pred)
r2_train = r2_score(y_train, y_train_pred)

mse_train, mae_train, ev_train, r2_train

# Look at testing metrics
mse_test = mean_squared_error(y_test, y_test_pred)
mae_test = mean_absolute_error(y_test, y_test_pred)
ev_test = explained_variance_score(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

mse_test, mae_test, ev_test, r2_test

# Plot learning curve to check for over/under fitting
train_sizes, train_scores, valid_scores =learning_curve(sgd,X_train, y_train)
plt.plot(train_sizes, train_scores.mean(axis=1), color='r')
plt.plot(train_sizes, valid_scores.mean(axis=1))

# Check Ridge Regression to make sure
from sklearn.linear_model import Ridge
ridge_regression = Ridge(alpha=0.0001, max_iter=1000, tol=1e-3)
ridge_regression.fit(X_train, y_train)

y_train_pred = ridge_regression.predict(X_train)
y_test_pred = ridge_regression.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mae_train = mean_absolute_error(y_train, y_train_pred)
ev_train = explained_variance_score(y_train, y_train_pred)
r2_train = r2_score(y_train, y_train_pred)

mse_test = mean_squared_error(y_test, y_test_pred)
mae_test = mean_absolute_error(y_test, y_test_pred)
ev_test = explained_variance_score(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

mse_train, mae_train, ev_train, r2_train

mse_test, mae_test, ev_test, r2_test

"""OLS model"""

import statsmodels.api as sm

# Use same features selected above from SGD
features = ['Temperature(째C)', 'Hour', 'Dew point temperature(째C)', 'Seasons_Winter', 'Seasons_Summer', 'Solar Radiation (MJ/m2)', 'Humidity(%)', 'Visibility (10m)', 'Functioning Day_Yes']

X = X[features]
#did not standardize for better interpretbility

X = sm.add_constant(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=5)

# OLS model
mod = sm.OLS(y_train, X_train)

res = mod.fit()

print(res.summary())

y_test_predict = res.predict(X_test)

sm.tools.eval_measures.rmse(y_test, y_test_predict)